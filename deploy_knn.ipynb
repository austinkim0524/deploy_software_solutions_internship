{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import genesis\n",
    "#nltk.download('genesis')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "genesis_ic = wn.ic(genesis, False, 0.0)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import spacy\n",
    "import re\n",
    "nlp = spacy.load('en_core_web_sm',disable=['ner','textcat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN_NLC_Classifer():\n",
    "    def __init__(self, k=1, distance_type = 'path'):\n",
    "        self.k = k\n",
    "        self.distance_type = distance_type\n",
    "\n",
    "    def convert_tag(self, tag):\n",
    "        tag_dict = {'N': 'n', 'J': 'a', 'R': 'r', 'V': 'v'}\n",
    "        try:\n",
    "            return tag_dict[tag[0]]\n",
    "        except KeyError:\n",
    "            return None\n",
    "\n",
    "    def doc_to_synsets(self, doc):\n",
    "        tokens = word_tokenize(doc+' ')       \n",
    "        l = []\n",
    "        tags = nltk.pos_tag([tokens[0] + ' ']) if len(tokens) == 1 else nltk.pos_tag(tokens)\n",
    "        for token, tag in zip(tokens, tags):\n",
    "            syntag = self.convert_tag(tag[1])\n",
    "            syns = wn.synsets(token, syntag)\n",
    "            if (len(syns) > 0):\n",
    "                l.append(syns[0])\n",
    "        return l\n",
    "    \n",
    "    def similarity_score(self, s1, s2, distance_type = 'path'):\n",
    "        s1_largest_scores = []\n",
    "\n",
    "        for i, s1_synset in enumerate(s1, 0):\n",
    "            max_score = 0\n",
    "            for s2_synset in s2:\n",
    "                if distance_type == 'path':\n",
    "                    score = s1_synset.path_similarity(s2_synset, simulate_root = False)\n",
    "                else:\n",
    "                    score = s1_synset.wup_similarity(s2_synset)                  \n",
    "                if score != None:\n",
    "                    if score > max_score:\n",
    "                        max_score = score\n",
    "              \n",
    "            if max_score != 0:\n",
    "                s1_largest_scores.append(max_score)\n",
    "          \n",
    "        mean_score = np.mean(s1_largest_scores)\n",
    "                 \n",
    "        return mean_score  \n",
    "\n",
    "def document_similarity(self,doc1, doc2):\n",
    "        synsets1 = self.doc_to_synsets(doc1)\n",
    "        synsets2 = self.doc_to_synsets(doc2)\n",
    "        return ((self.similarity_score(synsets1, synsets2) + self.similarity_score(synsets2, synsets1)) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Similarity Score:  0.7208613785670974\n"
     ]
    }
   ],
   "source": [
    "knn = KNN_NLC_Classifer()\n",
    "\n",
    "file1 = open(r\"C:\\Users\\Austin\\txt_file\\adapt_bulletin-adapt1-eng.txt\", mode = 'r', encoding = 'utf-8-sig')\n",
    "l1 = file1.read()\n",
    "file1.close()\n",
    "\n",
    "file2 = open(r\"C:\\Users\\Austin\\txt_file\\81363.txt\", mode = 'r', encoding = 'utf-8-sig')\n",
    "l2 = file2.read()\n",
    "file2.close()\n",
    "\n",
    "print(\"Test Similarity Score: \", document_similarity(knn, l1, l2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files \"81363\" and \"Adapt_bulletin-adapt1-eng\" (PDF's available on Github) have a 72% similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Similarity Score:  0.7321147529965923\n"
     ]
    }
   ],
   "source": [
    "file3 = open(r\"C:\\Users\\Austin\\txt_file\\ccp_impactonpeople.txt\", mode = 'r', encoding = 'utf-8-sig')\n",
    "l3 = file3.read()\n",
    "file3.close()\n",
    "\n",
    "file4 = open(r\"C:\\Users\\Austin\\txt_file\\Bruce_(2006)_AdaptingtoClimateChange_ARisk-basedGuideforONMunicipalities.txt\", mode = 'r', encoding = 'utf-8-sig')\n",
    "l4 = file4.read()\n",
    "file4.close()\n",
    "\n",
    "print(\"Test Similarity Score: \", document_similarity(knn, l3, l4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files \"ccp_impactonpeople\" and \"Bruce_(2006)_AdaptingtoClimateChange_ARisk-basedGuideforONMunicipalities\" (PDF's available on Github) have a 73% similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Similarity Score:  0.7144099232801115\n"
     ]
    }
   ],
   "source": [
    "file5 = open(r\"C:\\Users\\Austin\\txt_file\\public_guideline__principles_of_climate_adaptation_and_mitigation_for_engineers.txt\", mode = 'r', encoding = 'utf-8-sig')\n",
    "l5 = file5.read()\n",
    "file5.close()\n",
    "\n",
    "file6 = open(r\"C:\\Users\\Austin\\txt_file\\Spring_Flood_Fact_Sheet.txt\", mode = 'r', encoding = 'utf-8-sig')\n",
    "l6 = file6.read()\n",
    "file6.close()\n",
    "\n",
    "print(\"Test Similarity Score: \", document_similarity(knn, l5, l6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files \"public_guideline__principles_of_climate_adaptation_and_mitigation_for_engineers\" and \"Spring_Flood_Fact_Sheet\" (PDF's available on Github) have a 71% similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
